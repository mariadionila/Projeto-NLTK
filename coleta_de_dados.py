# -*- coding: utf-8 -*-
"""coleta de dados

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tCDHpkBRUswwKvS_8kjexlUaUcg4o3oi
"""

pip install google-api-python-client

import googleapiclient.discovery
import googleapiclient.errors

# --- Configurações ---
# Substitua pelo ID do vídeo do YouTube
VIDEO_ID = "FpsCzFGL1LE"

# Substitua pela sua chave de API do Google
API_KEY = "AIzaSyDYLFVi2ciHPJLnYtyPOZ691Rt9LTHA5Ko"

def get_video_comments(video_id, api_key):
    """
    Coleta os comentários de um vídeo do YouTube usando a API.
    """
    api_service_name = "youtube"
    api_version = "v3"

    # Cria o cliente para interagir com a API
    youtube = googleapiclient.discovery.build(
        api_service_name, api_version, developerKey=api_key
    )

    comments_list = []
    next_page_token = None

    try:
        while True:
            # Faz a requisição dos comentários
            request = youtube.commentThreads().list(
                part="snippet,replies",
                videoId=video_id,
                textFormat="plainText",
                maxResults=100,
                pageToken=next_page_token
            )
            response = request.execute()

            # Processa os comentários
            for item in response["items"]:
                comment_snippet = item["snippet"]["topLevelComment"]["snippet"]

                comment_data = {
                    "author": comment_snippet["authorDisplayName"],
                    "text": comment_snippet["textDisplay"],
                    "published_at": comment_snippet["publishedAt"],
                    "like_count": comment_snippet["likeCount"],
                }
                comments_list.append(comment_data)

                # Coleta as respostas, se existirem
                if "replies" in item:
                    for reply_item in item["replies"]["comments"]:
                        reply_snippet = reply_item["snippet"]
                        reply_data = {
                            "author": reply_snippet["authorDisplayName"],
                            "text": reply_snippet["textDisplay"],
                            "published_at": reply_snippet["publishedAt"],
                            "like_count": reply_snippet["likeCount"],
                            "is_reply": True
                        }
                        comments_list.append(reply_data)

            # Verifica se há mais páginas de comentários
            next_page_token = response.get("nextPageToken")
            if not next_page_token:
                break

    except googleapiclient.errors.HttpError as e:
        print(f"Ocorreu um erro: {e}")
        return None

    return comments_list

if __name__ == "__main__":
    print(f"Coletando comentários do vídeo: {VIDEO_ID}...")
    comments = get_video_comments(VIDEO_ID, API_KEY)

    if comments:
        print(f"Total de comentários coletados: {len(comments)}")

        # Exibe os primeiros 5 comentários para verificar
        print("\nPrimeiros 5 comentários:")
        for i in range(min(5, len(comments))):
            comment = comments[i]
            print("---")
            print(f"Autor: {comment['author']}")
            print(f"Texto: {comment['text']}")
            print(f"Curtidas: {comment['like_count']}")
            print(f"Data: {comment['published_at']}")

        # Você pode salvar os dados em um arquivo CSV ou JSON
        # Exemplo para salvar em JSON:
        import json
        with open("comentarios.json", "w", encoding="utf-8") as f:
            json.dump(comments, f, ensure_ascii=False, indent=4)
        print("\nComentários salvos em 'comentarios.json'.")